{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning to predict a new venue's popularity (star ratings) when it opens using the data available from yelp's existing venue ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ujson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('yelp_train_academic_dataset_business.json','rb') as yelp:\n",
    "    for ye in yelp:\n",
    "        data.append(ujson.loads(ye))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37938 entries, 0 to 37937\n",
      "Data columns (total 15 columns):\n",
      "attributes       37938 non-null object\n",
      "business_id      37938 non-null object\n",
      "categories       37938 non-null object\n",
      "city             37938 non-null object\n",
      "full_address     37938 non-null object\n",
      "hours            37938 non-null object\n",
      "latitude         37938 non-null float64\n",
      "longitude        37938 non-null float64\n",
      "name             37938 non-null object\n",
      "neighborhoods    37938 non-null object\n",
      "open             37938 non-null bool\n",
      "review_count     37938 non-null int64\n",
      "stars            37938 non-null float64\n",
      "state            37938 non-null object\n",
      "type             37938 non-null object\n",
      "dtypes: bool(1), float64(3), int64(1), object(10)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('stars',axis=1)\n",
    "y= df.stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = X_train.join(y_train)\n",
    "test = X_test.join(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city\n",
       "Ahwatukee               3.571429\n",
       "Anthem                  3.804348\n",
       "Apache Junction         3.610169\n",
       "Arcadia                 5.000000\n",
       "Atlanta                 3.500000\n",
       "Avondale                3.522727\n",
       "Black Canyon City       3.000000\n",
       "Bonnyrigg               3.750000\n",
       "Boulder City            4.035714\n",
       "Buckeye                 3.491525\n",
       "C Las Vegas             3.000000\n",
       "Cambridge               4.166667\n",
       "Carefree                3.760000\n",
       "Casa Grande             3.567568\n",
       "Cave Creek              3.939252\n",
       "Centennial Hills        3.000000\n",
       "Central City Village    3.500000\n",
       "Central Henderson       3.500000\n",
       "Chandler                3.682239\n",
       "Chandler-Gilbert        5.000000\n",
       "Clark County            3.500000\n",
       "Coolidge                3.571429\n",
       "Cottage Grove           3.000000\n",
       "Cramond                 3.500000\n",
       "Dalkeith                4.250000\n",
       "Dane                    4.500000\n",
       "De Forest               3.700000\n",
       "DeForest                4.100000\n",
       "Deforest                5.000000\n",
       "Eagan                   5.000000\n",
       "                          ...   \n",
       "Stockbridge             4.500000\n",
       "Stoughton               3.750000\n",
       "Summerlin               4.000000\n",
       "Summerlin South         3.250000\n",
       "Sun City                3.392157\n",
       "Sun City West           3.769231\n",
       "Sun Lakes               3.428571\n",
       "Sun Prairie             3.481132\n",
       "Sunrise                 3.000000\n",
       "Surprise                3.594231\n",
       "Tempe                   3.648449\n",
       "Tolleson                3.121212\n",
       "Tonopah                 3.666667\n",
       "Tonto Basin             4.000000\n",
       "Tortilla Flat           5.000000\n",
       "Verona                  3.875000\n",
       "Victoria Park           4.500000\n",
       "W Henderson             3.500000\n",
       "W Spring Valley         3.000000\n",
       "W Summerlin             3.500000\n",
       "Waddell                 4.500000\n",
       "Water of Leith          4.500000\n",
       "Waterloo                3.634454\n",
       "Waunakee                3.323529\n",
       "Whitney                 4.500000\n",
       "Wickenburg              3.708333\n",
       "Windsor                 3.400000\n",
       "Woolwich                5.000000\n",
       "Youngtown               4.111111\n",
       "chandler                5.000000\n",
       "Name: stars, Length: 149, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('city')['stars'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Estimator to predict star ratings using average rating of a city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class cityModel(BaseEstimator,RegressorMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self,X,y):\n",
    "        self.data = pd.DataFrame({'city':X,'stars':y})\n",
    "        self.avg = self.data.groupby('city')['stars'].mean()\n",
    "        return self\n",
    "    def predict(self,X):\n",
    "        return self.avg.loc[X] if X in self.avg.index.values else 2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cityModel()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =cityModel()\n",
    "model.fit(train.city,train.stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8\n",
      "2.8\n"
     ]
    }
   ],
   "source": [
    "print model.predict('Delhi')\n",
    "print model.predict('Redmond')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom transformer to select relevant columns in order to predict star ratings using neighborhood dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class latlongModel(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,column1,column2):\n",
    "        self.column1 = column1\n",
    "        self.column2 = column2\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self,X):\n",
    "        self.result = zip(X[self.column1],X[self.column2])\n",
    "        return self.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer = latlongModel('latitude','longitude')\n",
    "#X_train_trans=transformer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print X_train_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('trans', latlongModel(column1='latitude', column2='longitude')), ('estimator', KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "          weights='uniform'))])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting a pipeline for transforming the data and fitting the model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "reg = Pipeline([('trans',latlongModel('latitude','longitude')),\n",
    "               ('estimator',KNeighborsRegressor(n_neighbors=3))])\n",
    "\n",
    "reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.83333333,  3.33333333,  3.5       , ...,  3.5       ,\n",
       "        4.33333333,  2.66666667])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.21053764500254091"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['estimator__metric_params',\n",
       " 'estimator__p',\n",
       " 'trans__column1',\n",
       " 'trans__column2',\n",
       " 'estimator__metric',\n",
       " 'estimator__leaf_size',\n",
       " 'estimator__n_jobs',\n",
       " 'estimator',\n",
       " 'steps',\n",
       " 'estimator__weights',\n",
       " 'estimator__n_neighbors',\n",
       " 'trans',\n",
       " 'estimator__algorithm']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('transformer', latlongModel(column1='latitude', column2='longitude')), ('estimator', KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "          weights='uniform'))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'estimator__n_neighbors': (5, 7, 10)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyper parameter tuning to predict star ratings using neighborhood dynamics.\n",
    "\n",
    "param_grid = {'estimator__n_neighbors': (5,7,10)}\n",
    "\n",
    "pipe = Pipeline ([\n",
    "    ('transformer',latlongModel('latitude','longitude')),\n",
    "    ('estimator', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.65,  3.5 ,  3.85, ...,  3.9 ,  3.85,  3.65])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator__n_neighbors': 10}\n"
     ]
    }
   ],
   "source": [
    "print grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('transformer', latlongModel(column1='latitude', column2='longitude')), ('estimator', KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "          weights='uniform'))])\n"
     ]
    }
   ],
   "source": [
    "print grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0413267365233\n"
     ]
    }
   ],
   "source": [
    "print grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom transformer to perform feature extraction on venue category in order to predict star ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "result =[]\n",
    "value = 1\n",
    "count =0\n",
    "for row in X_train['categories']:\n",
    "    d = dict()\n",
    "    for i in range(len(row)):\n",
    "        count =+1\n",
    "        d.update({row[i]:value})\n",
    "        print d\n",
    "    result.append(d)    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class categoryModel(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,column):\n",
    "        self.column = column\n",
    "        \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        self.result =[]\n",
    "        value = 1\n",
    "        for row in X[self.column]:\n",
    "            d = dict()\n",
    "            for i in range(len(row)):\n",
    "                d.update({row[i]:value})\n",
    "            self.result.append(d)\n",
    "        return self.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = categoryModel('categories')\n",
    "#result=model.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "#v = DictVectorizer(sparse=False)\n",
    "#X = v.fit_transform(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows in the sparse vector :  28453\n",
      "No. of columns in the sparse vector :  694\n",
      "Shape of sparse vector : (28453, 694)\n"
     ]
    }
   ],
   "source": [
    "# Validating the shape of X\n",
    "#all_keys = set().union(*(d.keys() for d in result))\n",
    "\n",
    "#print \"No. of rows in the sparse vector : \", X_train.shape[0]\n",
    "#print \"No. of columns in the sparse vector : \", len(all_keys)\n",
    "#print \"Shape of sparse vector :\", X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('trans', categoryModel(column='categories')), ('vect', DictVectorizer(dtype=<type 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=False)), ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline to custom fit and transform the venue category, generate sparse feature vector and fit a regularized linear model\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "pipeline = Pipeline([('trans',categoryModel('categories')),\n",
    "                     ('vect',DictVectorizer(sparse=False)),\n",
    "                     ('lasso', Lasso()),\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.67335606,  3.67335606,  3.67335606, ...,  3.67335606,\n",
       "        3.67335606,  3.67335606])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.8927106189579064e-06"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom transformer to flatten venue's json format attribute in order to perform feature extraction and prediction of star rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class knnModel(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,column):\n",
    "        self.column = column\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        \n",
    "        def flatten_json(y):\n",
    "            out = {}\n",
    "\n",
    "            def flatten(x, name=''):\n",
    "                        if type(x) is dict:\n",
    "                            for a in x:\n",
    "                                flatten(x[a], name + a + '_')\n",
    "                        elif type(x) is list:\n",
    "                            i = 0\n",
    "                            for a in x:\n",
    "                                flatten(a, name + str(i) + '_')\n",
    "                                i += 1\n",
    "                        elif type(x) is unicode:\n",
    "                             flatten(1, name + str(x) + '_')\n",
    "\n",
    "                        elif type(x) is bool:\n",
    "                             flatten(int(x), name)\n",
    "                        else:\n",
    "                            out[name[:-1]] = x\n",
    "\n",
    "            flatten(y)\n",
    "            return out\n",
    "    \n",
    "        self.attrlist = []\n",
    "        self.attr = X[self.column].tolist()\n",
    "        \n",
    "        for attr in self.attr:\n",
    "            flat = flatten_json(attr)\n",
    "            self.attrlist.append(flat)\n",
    "            \n",
    "        return self.attrlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "##knnmodel = knnModel('attributes')\n",
    "##knnmodel.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "##for row in X_train.attributes:\n",
    "   ## print row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('trans', knnModel(column='attributes')), ('vect', DictVectorizer(dtype=<type 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=False)), ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Piple line to implement custom transformer to flatten the json column, dictvectorizer to generate sparse vector and estimator to fit a regularized linear model.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "pipl = Pipeline([\n",
    "    ('trans',knnModel('attributes')),\n",
    "    ('vect',DictVectorizer(sparse=False)),\n",
    "    #('linreg',LinearRegression())\n",
    "    ('lasso',Lasso())\n",
    "])\n",
    "\n",
    "pipl.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.67335606,  3.67335606,  3.67335606, ...,  3.67335606,\n",
       "        3.67335606,  3.67335606])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.8927106189579064e-06"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipl.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline to implement full model using Features Union to predict star ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "\n",
    "class fullModel(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        return self.model.fit(X,y)\n",
    "    \n",
    "    def transform(self,X):\n",
    "        return [ [value] for value in self.model.predict(X)]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "allmodel = FeatureUnion([\n",
    "    ('latlong',Pipeline([\n",
    "        ('transformer',latlongModel('latitude','longitude')),\n",
    "        ('estimator', fullModel(KNeighborsRegressor())),\n",
    "    ])),\n",
    "    \n",
    "    ('category',Pipeline([\n",
    "        ('transformer',categoryModel('categories')),\n",
    "        ('Vectorizer',DictVectorizer(sparse=False)),\n",
    "        ('estimator',fullModel(Lasso())),\n",
    "    ])),\n",
    "    \n",
    "    ('attribute',Pipeline([\n",
    "        ('transformer',knnModel('attributes')),\n",
    "        ('Vectorizer',DictVectorizer(sparse=False)),\n",
    "        ('estimator',fullModel(LinearRegression()))\n",
    "    ])),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('latlong', Pipeline(steps=[('transformer', latlongModel(column1='latitude', column2='longitude')), ('estimator', fullModel(model=KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "          weights='u..., fullModel(model=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)))]))],\n",
       "       transformer_weights=None)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.1       ,  3.67335606,  3.55464887],\n",
       "       [ 3.2       ,  3.67335606,  3.33948278],\n",
       "       [ 3.7       ,  3.67335606,  3.55994466],\n",
       "       ..., \n",
       "       [ 3.8       ,  3.67335606,  2.95496551],\n",
       "       [ 4.        ,  3.67335606,  3.24125399],\n",
       "       [ 3.        ,  3.67335606,  3.66016412]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions are peformed using transform method defined in fullModel transformer\n",
    "allmodel.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
